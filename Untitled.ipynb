{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "import json\n",
    "\n",
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import secure\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, SnapshotObjectType, OperationStatusType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(\"Connexus\")\n",
    "\n",
    "## NOTE: Need secure.py file from localhost, will not run otherwise\n",
    "KEY = secure.KEY\n",
    "ENDPOINT = secure.ENDPOINT\n",
    "PERSON_GROUP_ID = 'fourteenth-batch'\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(file_name):\n",
    "    image = open(file_name, 'r+b')\n",
    "    # Detect faces\n",
    "    face_ids = []\n",
    "    faces = face_client.face.detect_with_stream(image)\n",
    "    if not faces:\n",
    "        raise Exception('No face detected from image.')\n",
    "    for face in faces:\n",
    "        face_ids.append(face.face_id)\n",
    "    image.close()\n",
    "    return faces, face_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "\n",
    "    return ((left, top), (right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(file_name, detected_faces=[]):\n",
    "    data = open(file_name, 'rb')\n",
    "    img = Image.open(data)\n",
    "\n",
    "    # For each face returned use the face rectangle and draw a red box.\n",
    "    print('Drawing rectangle around face... see popup for results.')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in detected_faces:\n",
    "        draw.rectangle(get_rectangle(face), outline='red')\n",
    "\n",
    "    # Display the image in the users default image browser.\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_person_group(names):\n",
    "    print('Person group:', PERSON_GROUP_ID)\n",
    "    face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID)\n",
    "    name_map = {}\n",
    "    for name in names:\n",
    "        name_map[name] = face_client.person_group_person.create(PERSON_GROUP_ID, name)\n",
    "    return name_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_person_group(names, name_map):\n",
    "    for name in names:\n",
    "        #TODO: CONVERT FROM JPG\n",
    "        images = [file for file in glob.glob('*.png') if file.startswith(name)]\n",
    "        for image in images:\n",
    "            data = open(image, 'r+b')\n",
    "            face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, name_map[name].person_id, data)\n",
    "    print('Training the person group...')\n",
    "    # Train the person group\n",
    "    face_client.person_group.train(PERSON_GROUP_ID)\n",
    "\n",
    "    while (True):\n",
    "        training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "        print(\"Training status: {}.\".format(training_status.status))\n",
    "        print()\n",
    "        if (training_status.status is TrainingStatusType.succeeded):\n",
    "            break\n",
    "        elif (training_status.status is TrainingStatusType.failed):\n",
    "            sys.exit('Training the person group has failed.')\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_child( file_name):\n",
    "    faces, face_ids = detect_faces(file_name)\n",
    "    show_image(file_name, faces)\n",
    "    results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "    confidence_vals = []\n",
    "    for person in results:\n",
    "        print(person.candidates[0].confidence)\n",
    "        confidence_vals.append(person.candidates[0].confidence)\n",
    "    return confidence_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person group: fourteenth-batch\n",
      "Training the person group...\n",
      "Training status: running.\n",
      "\n",
      "Training status: succeeded.\n",
      "\n",
      "Drawing rectangle around face... see popup for results.\n",
      "0.80936\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'confidences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-04178a9449d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Step 4: Return confidence level\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfidences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'confidences' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "names = [\"blue-ivy\", \"zahara\", \"maddox\", \"eddie\", \"blackish\"]\n",
    "test_image = \"test-blackish.png\"\n",
    "# Step 0: Load face client\n",
    "#face_client = load_client()\n",
    "\n",
    "# Step 1: Create person_group with correct pictures\n",
    "name_map = create_person_group(names=names)\n",
    "\n",
    "# Step 2: Train person group on correct images\n",
    "train_person_group(names, name_map)\n",
    "\n",
    "# Step 3: Identify from test image\n",
    "# confidences = identify_child(file_name=test_image)\n",
    "\n",
    "faces, face_ids = detect_faces(test_image)\n",
    "show_image(test_image, faces)\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "confidence_vals = []\n",
    "for person in results:\n",
    "    print(person.candidates[0].confidence)\n",
    "    confidence_vals.append(person.candidates[0].confidence)\n",
    "confidence_vals\n",
    "\n",
    "# Step 4: Return confidence level\n",
    "# print(confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_face = results[0].face_id\n",
    "verify_result_same = face_client.face.verify_face_to_face(new_face, face_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80936\n",
      "{'additional_properties': {}, 'person_id': '7e145d9b-0a9c-4195-9811-b2539779ee2a', 'confidence': 0.80936}\n"
     ]
    }
   ],
   "source": [
    "for person in results:\n",
    "    print(person.candidates[0].confidence)\n",
    "    print(results[0].candidates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b17229d1-b3f3-4ce1-86e7-91183c2cb369\n",
      "b17229d1-b3f3-4ce1-86e7-91183c2cb369\n"
     ]
    }
   ],
   "source": [
    "print(results[0].candidates[0])\n",
    "print(face_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = face_client.person_group_person.get(PERSON_GROUP_ID, results[0].candidates[0].person_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_result_same = face_client.face.verify_face_to_person(face_id=face_ids[0], person_group_id=PERSON_GROUP_ID, person_id=results[0].candidates[0].person_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'is_identical': True, 'confidence': 0.80936}\n"
     ]
    }
   ],
   "source": [
    "print(verify_result_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blackish\n",
      "Drawing rectangle around face... see popup for results.\n"
     ]
    }
   ],
   "source": [
    "for key in name_map:\n",
    "    if name_map[key].person_id == results[0].candidates[0].person_id:\n",
    "        print(key)\n",
    "        images = [file for file in glob.glob('*.png') if file.startswith(key)]\n",
    "        for image in images[:1]:\n",
    "            show_image(image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing rectangle around face... see popup for results.\n"
     ]
    }
   ],
   "source": [
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "\n",
    "    return ((left, top), (right, bottom))\n",
    "\n",
    "\n",
    "# Download the image from the url\n",
    "response = requests.get(single_face_image_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# For each face returned use the face rectangle and draw a red box.\n",
    "print('Drawing rectangle around face... see popup for results.')\n",
    "draw = ImageDraw.Draw(img)\n",
    "for face in detected_faces:\n",
    "    draw.rectangle(getRectangle(face), outline='red')\n",
    "\n",
    "# Display the image in the users default image browser.\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in the Person Group Operations,  Snapshot Operations, and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = 'my-unique-person-group'\n",
    "\n",
    "# Used for the Snapshot and Delete Person Group examples.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person group: my-unique-person-group\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID)\n",
    "\n",
    "# Define woman friend\n",
    "woman = face_client.person_group_person.create(PERSON_GROUP_ID, \"Woman\")\n",
    "# Define man friend\n",
    "man = face_client.person_group_person.create(PERSON_GROUP_ID, \"Man\")\n",
    "# Define child friend\n",
    "child = face_client.person_group_person.create(PERSON_GROUP_ID, \"Child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect faces and register to correct person\n",
    "'''\n",
    "# Find all jpeg images of friends in working directory\n",
    "woman_images = [file for file in glob.glob('*.jpg') if file.startswith(\"woman\")]\n",
    "man_images = [file for file in glob.glob('*.jpg') if file.startswith(\"man\")]\n",
    "child_images = [file for file in glob.glob('*.jpg') if file.startswith(\"child\")]\n",
    "\n",
    "# Add to a woman person\n",
    "for image in woman_images:\n",
    "    w = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, woman.person_id, w)\n",
    "\n",
    "# Add to a man person\n",
    "for image in man_images:\n",
    "    m = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, man.person_id, m)\n",
    "\n",
    "# Add to a child person\n",
    "for image in child_images:\n",
    "    ch = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, child.person_id, ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the person group...\n",
      "Training status: running.\n",
      "\n",
      "Training status: succeeded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train PersonGroup\n",
    "'''\n",
    "print()\n",
    "print('Training the person group...')\n",
    "# Train the person group\n",
    "face_client.person_group.train(PERSON_GROUP_ID)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get test image\n",
    "test_image_array = [file for file in glob.glob('*.jpg') if file.startswith(\"test\")]\n",
    "image = open(test_image_array[0], 'r+b')\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "faces = face_client.face.detect_with_stream(image)\n",
    "for face in faces:\n",
    "    face_ids.append(face.face_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing rectangle around face... see popup for results.\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/test-image-person-group.jpg')\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# For each face returned use the face rectangle and draw a red box.\n",
    "print('Drawing rectangle around face... see popup for results.')\n",
    "draw = ImageDraw.Draw(img)\n",
    "for face in faces:\n",
    "    draw.rectangle(getRectangle(face), outline='red')\n",
    "\n",
    "# Display the image in the users default image browser.\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying faces in test-image-person-group.jpg\n",
      "Person for face ID 93e22523-b3ec-4212-8e37-0db2288c29d7 is identified in test-image-person-group.jpg with a confidence of 0.92387.\n",
      "Person for face ID 026520da-fe50-4a53-b3c4-f21bec72898e is identified in test-image-person-group.jpg with a confidence of 0.93316.\n"
     ]
    }
   ],
   "source": [
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print('Identifying faces in {}'.format(os.path.basename(image.name)))\n",
    "if not results:\n",
    "    print('No person identified in the person group for faces from {}.'.format(os.path.basename(image.name)))\n",
    "for person in results:\n",
    "    print('Person for face ID {} is identified in {} with a confidence of {}.'.format(person.face_id, os.path.basename(image.name), person.candidates[0].confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92387\n",
      "0.93316\n"
     ]
    }
   ],
   "source": [
    "for person in results:\n",
    "    print(person.candidates[0].confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'face_id': '93e22523-b3ec-4212-8e37-0db2288c29d7', 'candidates': [<azure.cognitiveservices.vision.face.models._models_py3.IdentifyCandidate object at 0x0000019A561104E0>]}\n",
      "{'additional_properties': {}, 'face_id': '026520da-fe50-4a53-b3c4-f21bec72898e', 'candidates': [<azure.cognitiveservices.vision.face.models._models_py3.IdentifyCandidate object at 0x0000019A56110438>]}\n"
     ]
    }
   ],
   "source": [
    "for person in results:\n",
    "    print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = face_client.person_group_person.get(PERSON_GROUP_ID, results[0].candidates[0].person_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pfi in x.persisted_face_ids:\n",
    "    new = face_client.person_group_person.get_face(PERSON_GROUP_ID, x.person_id, pfi)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'persisted_face_id': '0a9dbf76-5d76-458f-ade5-c4ceae3fc074', 'user_data': None}\n"
     ]
    }
   ],
   "source": [
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We have confirmed this child as a match with 80.9% confidence'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence = [0.891232234]\n",
    "\"We have confirmed this child as a match with {0:.{1}f}% confidence\".format(confidence_vals[0]*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
